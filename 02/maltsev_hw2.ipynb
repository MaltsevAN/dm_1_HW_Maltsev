{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №2 - Дерево решений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** до 27 марта 2018, 06:00   \n",
    "**Штраф за опоздание:** -2 балла после 06:00 27 марта, -4 балла после 06:00 3 апреля, -6 баллов после 06:00 10 апреля\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла   \n",
    "\n",
    "\n",
    "Присылать ДЗ необходимо в виде ссылки на свой github репозиторий в slack @alkhamush\n",
    "Необходимо в slack создать таск в приватный чат:   \n",
    "/todo Фамилия Имя *ссылка на гитхаб* @alkhamush   \n",
    "Пример:   \n",
    "/todo Ксения Стройкова https://github.com/stroykova/spheremailru/stroykova_hw2.ipynb @alkhamush   \n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Задание 1 (2 баллов)\n",
    "Разберитесь в коде MyDecisionTreeClassifier, который уже частично реализован. В комментариях, где написано \"Что делает этот блок кода?\", ответьте на этот вопрос. Допишите код там, где написано \"Ваш код\". Ваша реализация дерева должна работать по точности не хуже DecisionTreeClassifier из sklearn. Точность проверяется на wine и Speed Dating Data.\n",
    "\n",
    "###### Задание 2 (2 балла)\n",
    "Добиться скорости работы на fit сравнимой со sklearn wine и Speed Dating Data. \n",
    "Для этого используем numpy. \n",
    "\n",
    "###### Задание 3 (2 балла)\n",
    "Продемонстрируйте умение работать с Pipeline на данных Speed Dating Data и DecisionTreeClassifier. Нужно в pipeline произвести все необходимые преобразования данных и в конце обучить модель. Задание реализуйте под пунктом Задание 3 (уже написано ниже)\n",
    "\n",
    "###### Задание 4 (2 балла)\n",
    "Добавьте функционал, который определяет значения feature importance. Выведите 10 главных фичей под пунктом Задание 4 (уже написано ниже) для MyDecisionTreeClassifier и DecisionTreeClassifier так, чтобы сразу были видны выводы и по MyDecisionTreeClassifier, и по DecisionTreeClassifier. Используем данные Speed Dating Data.\n",
    "\n",
    "###### Задание 5 (2 балла)\n",
    "С помощью GridSearchCV или RandomSearchCV подберите наиболее оптимальные параметры для случайного леса (Выберете 2-3 параметра). Используем данные Speed Dating Data. Задание реализуйте под пунктом Задание 5 (уже написано ниже)\n",
    "\n",
    "\n",
    "**Штрафные баллы:**\n",
    "\n",
    "1. Невыполнение PEP8 -1 балл\n",
    "2. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw2.ipynb) -1 балл\n",
    "3. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -1 балл\n",
    "4. При оформлении ДЗ нужно пользоваться данным файлом в качестве шаблона. Не нужно удалять и видоизменять написанный код и текст. В противном случае -1 балл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pycodestyle_magic extension is already loaded. To reload it, use:\n",
      "  %reload_ext pycodestyle_magic\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "\n",
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=None,\n",
    "                 sufficient_share=1.0, criterion='gini', max_features=None):\n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        self.feature_importances_ = None\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            print('invalid criterion name')\n",
    "            raise\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features == None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print('invalid max_features name')\n",
    "            raise\n",
    "\n",
    "    def __gini(self, l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        return (l_s / (l_s + r_s)).reshape(l_s.shape[0]) * (\n",
    "                1 - ((l_c / l_s) ** 2).sum(axis=1)) + (\n",
    "                       r_s / (l_s + r_s)).reshape(r_s.shape[0]) * (\n",
    "                       1 - ((r_c / r_s) ** 2).sum(axis=1))\n",
    "\n",
    "    def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "        return -((l_s / (l_s + r_s)).reshape(l_s.shape[0]) * np.nansum(\n",
    "            ((l_c / l_s) * np.log2((l_c / l_s))), axis=1) +\n",
    "                 (r_s / (l_s + r_s)).reshape(r_s.shape[0]) * np.nansum(\n",
    "                    ((r_c / r_s) * np.log2((r_c / r_s))), axis=1))\n",
    "\n",
    "    def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "        return (l_s / (l_s + r_s)).reshape(l_s.shape[0]) * (\n",
    "                1 - (l_c / l_s).max(axis=1)) + (r_s / (l_s + r_s)).reshape(\n",
    "            r_s.shape[0]) * (\n",
    "                       1 - (r_c / r_s).max(axis=1))\n",
    "\n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return np.array(feature_ids[:max(1, int(np.sqrt(n_feature)))])\n",
    "\n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return np.array(feature_ids[:max(1, int(np.log2(n_feature)))])\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        return np.array(range(n_feature))\n",
    "\n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        # Что делает этот блок кода?\n",
    "        # Сортируем признак x по возрастанию и получаем соответствующий ему y,\n",
    "        # плюс получаем количество классов.\n",
    "        sorted_x, sorted_y = self.__sort_samples(x, y)\n",
    "        class_number = np.unique(y).shape[0]\n",
    "\n",
    "        # Что делает этот блок кода?\n",
    "        # Получаем правые границы(где значение вектора y меняет класс),\n",
    "        # предварительо обрезав границы по бокам\n",
    "        splitted_sorted_y = sorted_y[\n",
    "                            self.min_samples_split:-self.min_samples_split]\n",
    "        r_border_ids = \\\n",
    "            np.where(splitted_sorted_y[:-1] != splitted_sorted_y[1:])[0] + (\n",
    "                    self.min_samples_split + 1)\n",
    "        if len(r_border_ids) != 0:\n",
    "\n",
    "            # Что делает этот блок кода?\n",
    "            # Получили число элементов принадлежащих одному класса\n",
    "            # до правой границы - eq_el_count\n",
    "            # Создаем матрицу, где число строк - число смен классов,\n",
    "            # а число столбцов - число классов заполненную нулями -one_hot_code\n",
    "            # В каждой строке матрицы помечаем,\n",
    "            # какой класс был до смены, -  единицей\n",
    "            # Далее вместо единицы в предыдущем классе,\n",
    "            # получаем число элементов данного класса,\n",
    "            # предшествущих границе из r_border_ids и записываем\n",
    "            # это в новую таблицу class_increments\n",
    "            # Делаем корректировку и в 0 строчке данной таблице дописываем\n",
    "            # элементры, встречавшиеся в первых min_samples_split\n",
    "            eq_el_count = r_border_ids - np.append([self.min_samples_split],\n",
    "                                                   r_border_ids[:-1])\n",
    "            one_hot_code = np.zeros(\n",
    "                (r_border_ids.shape[0], np.max(sorted_y) + 1))\n",
    "            one_hot_code[\n",
    "                np.arange(r_border_ids.shape[0]), sorted_y[\n",
    "                    r_border_ids - 1]] = 1\n",
    "            class_increments = one_hot_code * eq_el_count.reshape(-1, 1)\n",
    "            class_increments[0] = class_increments[0] + np.bincount(\n",
    "                sorted_y[:self.min_samples_split],\n",
    "                minlength=np.max(sorted_y) + 1)\n",
    "        else:\n",
    "            splitted_sorted_y = sorted_y\n",
    "            r_border_ids = \\\n",
    "                np.where(splitted_sorted_y[:-1] != splitted_sorted_y[1:])[\n",
    "                    0] + 1\n",
    "            eq_el_count = r_border_ids - np.append([0], r_border_ids[:-1])\n",
    "            one_hot_code = np.zeros(\n",
    "                (r_border_ids.shape[0], np.max(sorted_y) + 1))\n",
    "            one_hot_code[\n",
    "                np.arange(r_border_ids.shape[0]), sorted_y[\n",
    "                    r_border_ids - 1]] = 1\n",
    "            class_increments = one_hot_code * eq_el_count.reshape(-1, 1)                \n",
    "\n",
    "        # Что делает этот блок кода?\n",
    "        # Получаем суммарное число элементов каждого\n",
    "        # типа левее границы - l_class_count -\n",
    "        # Получаем суммарное число элементов каждого типа правее\n",
    "        # границы(включая элемент на границе) - r_class_count\n",
    "        # И соответственно число элементов в каждой строке\n",
    "        # для  l_class_count - l_sizes, аналогично для r_class_count\n",
    "        l_class_count = np.cumsum(class_increments, axis=0)\n",
    "        r_class_count = np.bincount(sorted_y) - l_class_count\n",
    "        l_sizes = r_border_ids.reshape(l_class_count.shape[0], 1)\n",
    "        r_sizes = sorted_y.shape[0] - l_sizes\n",
    "\n",
    "        # Что делает этот блок кода?\n",
    "        # Считаем улучшение меру неопределенности\n",
    "        # для каждого - получаем вектор gs\n",
    "        # Записываем в idx индекс наилучшего разбиения по признаку\n",
    "        gs = self.G_function(l_class_count, l_sizes, r_class_count, r_sizes)\n",
    "        idx = np.argmin(gs)\n",
    "\n",
    "        # Что делает этот блок кода?\n",
    "        # Получает индекс первого элемента в новом классе\n",
    "        # при наилучшем разбиении\n",
    "        # Возвращаем наименьшую меру неоприделенности и , средние значения\n",
    "        # признака, при которых целевой класс \"меняется\"\n",
    "        left_el_id = l_sizes[idx][0]\n",
    "        treshold = (sorted_x[left_el_id - 1] + sorted_x[left_el_id]) / 2.0\n",
    "        return gs[idx], treshold\n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth, pred_f=-1):\n",
    "        y_bincount = np.bincount(y, minlength=np.unique(y).shape[0])\n",
    "        y_count = np.max(y_bincount / np.sum(y_bincount))\n",
    "        if (self.max_depth is None):\n",
    "            is_leaf = (y.shape[0] < self.min_samples_split or\n",
    "                       y_count >= self.sufficient_share)\n",
    "        else:\n",
    "            is_leaf = (depth >= self.max_depth or\n",
    "                       y.shape[0] < self.min_samples_split or\n",
    "                       y_count >= self.sufficient_share)\n",
    "        if (is_leaf):\n",
    "            mode, count = stats.mode(y)\n",
    "            self.tree[node_id] = [self.__class__.LEAF_TYPE, mode[0], y_count]\n",
    "        else:\n",
    "            feature_ids = self.get_feature_ids(x.shape[1])\n",
    "            gs_features = np.zeros((feature_ids.shape[0],), dtype=np.float32)\n",
    "            threshold_features = np.zeros((feature_ids.shape[0],),\n",
    "                                          dtype=np.float32)\n",
    "            for i, f_id in enumerate(feature_ids):\n",
    "                gs_features[i], threshold_features[i] = self.__find_threshold(\n",
    "                    x[:, f_id], y)\n",
    "            gs_arg = np.argmin(gs_features)\n",
    "            gs_min = np.where(gs_features == gs_features[gs_arg])\n",
    "            cur_idn = np.random.choice(gs_min[0])\n",
    "            x_left, x_right, y_left, y_right = self.__div_samples(\n",
    "                x, y, feature_ids[cur_idn], threshold_features[cur_idn])\n",
    "            if (x_left.shape[0] != 0 and x_right.shape[0] != 0):\n",
    "                p = y_bincount / np.sum(y_bincount)\n",
    "                ig = ((1 - (p ** 2).sum()) - gs_features[gs_arg]) * np.sum(\n",
    "                    y_bincount) / self._X_size\n",
    "                self.feature_importances_[feature_ids[cur_idn]] += ig\n",
    "                self.tree[node_id] = [self.__class__.NON_LEAF_TYPE,\n",
    "                                      feature_ids[cur_idn],\n",
    "                                      threshold_features[cur_idn]]\n",
    "                self.__fit_node(x_left, y_left, 2 * node_id + 1, depth + 1,\n",
    "                                pred_f)\n",
    "                self.__fit_node(x_right, y_right, 2 * node_id + 2, depth + 1,\n",
    "                                pred_f)\n",
    "            else:\n",
    "                if (x_left.shape[0] == 0):\n",
    "                    mode, count = stats.mode(y_right)\n",
    "                    y_bincount = np.bincount(y,\n",
    "                                             minlength=np.unique(y).shape[0])\n",
    "                    y_count = np.max(y_bincount / np.sum(y_bincount))\n",
    "                    self.tree[node_id] = [self.__class__.LEAF_TYPE, mode[0],\n",
    "                                          y_count]\n",
    "                else:\n",
    "                    mode, count = stats.mode(y_left)\n",
    "                    y_bincount = np.bincount(y,\n",
    "                                             minlength=np.unique(y).shape[0])\n",
    "                    y_count = np.max(y_bincount / np.sum(y_bincount))\n",
    "                    self.tree[node_id] = [self.__class__.LEAF_TYPE, mode[0],\n",
    "                                          y_count]\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self._X_size = x.shape[0]\n",
    "        self.feature_importances_ = np.zeros((x.shape[1],))\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.__fit_node(x, y, 0, 0)\n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "\n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.8 ms, sys: 40 µs, total: 6.84 ms\n",
      "Wall time: 5.14 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.2 ms, sys: 3.99 ms, total: 34.2 ms\n",
      "Wall time: 31.4 ms\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9474747474747475"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('speed-dating-experiment/Speed Dating Data.csv',\n",
    "                 encoding='cp1251')\n",
    "df = df.iloc[:, :97]\n",
    "df = df.drop(['id'], axis=1)\n",
    "df = df.drop(['idg'], axis=1)\n",
    "df.drop_duplicates(subset=['iid']).gender.value_counts()\n",
    "df.drop_duplicates(subset=['iid']).condtn.value_counts()\n",
    "df = df.drop(['condtn'], axis=1)\n",
    "df = df.drop(['round'], axis=1)\n",
    "df = df.drop(['position', 'positin1'], axis=1)\n",
    "df = df.drop(['order'], axis=1)\n",
    "df = df.drop(['partner'], axis=1)\n",
    "df = df.drop(['age_o', 'race_o', 'pf_o_att',\n",
    "              'pf_o_sin', 'pf_o_int',\n",
    "              'pf_o_fun', 'pf_o_amb', 'pf_o_sha',\n",
    "              'dec_o', 'attr_o', 'sinc_o', 'intel_o', 'fun_o',\n",
    "              'amb_o', 'shar_o', 'like_o', 'prob_o', 'met_o'], axis=1)\n",
    "df.drop_duplicates('iid').age.isnull().sum()\n",
    "df = df.dropna(subset=['age'])\n",
    "df.field_cd.isnull().sum()\n",
    "df.loc[:, 'field_cd'] = df.loc[:, 'field_cd'].fillna(0)\n",
    "df = df.drop(['field'], axis=1)\n",
    "df = df.drop(['undergra'], axis=1)\n",
    "df.loc[:, 'mn_sat'] = df.loc[:, 'mn_sat'].str.replace(',', '').astype(np.float)\n",
    "df.loc[:, 'mn_sat'] = df.mn_sat.fillna(-999)\n",
    "df.loc[:, 'tuition'] = df.loc[:, 'tuition'].str.replace(',', '').astype(\n",
    "    np.float)\n",
    "df.loc[:, 'tuition'] = df.tuition.fillna(-999)\n",
    "df = df.dropna(subset=['imprelig', 'imprace'])\n",
    "df = df.drop(['from', 'zipcode'], axis=1)\n",
    "df.loc[:, 'income'] = df.loc[:, 'income'].str.replace(',', '').astype(np.float)\n",
    "df.loc[:, 'income'] = df.loc[:, 'income'].fillna(-999)\n",
    "df = df.dropna(subset=['date'])\n",
    "df.loc[:, 'career_c'] = df.loc[:, 'career_c'].fillna(0)\n",
    "df = df.drop(['career'], axis=1)\n",
    "df = df.drop(['sports', 'tvsports', 'exercise', 'dining', 'museums', 'art',\n",
    "              'hiking', 'gaming', 'clubbing', 'reading', 'tv', 'theater',\n",
    "              'movies', 'concerts', 'music', 'shopping', 'yoga'], axis=1)\n",
    "df = df.drop(['expnum'], axis=1)\n",
    "feat = ['iid', 'wave', 'attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1',\n",
    "        'shar1_1']\n",
    "temp = df.drop_duplicates(subset=['iid', 'wave']).loc[:, feat]\n",
    "temp.loc[:, 'totalsum'] = temp.iloc[:, 2:].sum(axis=1)\n",
    "df.loc[:, 'temp_totalsum'] = df.loc[:,\n",
    "                             ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1',\n",
    "                              'amb1_1', 'shar1_1']].sum(axis=1)\n",
    "df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1']] = \\\n",
    "    (df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1',\n",
    "                'shar1_1']].T / df.loc[:, 'temp_totalsum'].T).T * 100\n",
    "feat = ['iid', 'wave', 'attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1',\n",
    "        'shar2_1']\n",
    "temp = df.drop_duplicates(subset=['iid', 'wave']).loc[:, feat]\n",
    "temp.loc[:, 'totalsum'] = temp.iloc[:, 2:].sum(axis=1)\n",
    "df.loc[:, 'temp_totalsum'] = df.loc[:,\n",
    "                             ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1',\n",
    "                              'amb2_1', 'shar2_1']].sum(axis=1)\n",
    "df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1']] = \\\n",
    "    (df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1',\n",
    "                'shar2_1']].T / df.loc[:, 'temp_totalsum'].T).T * 100\n",
    "df = df.drop(['temp_totalsum'], axis=1)\n",
    "for i in [4, 5]:\n",
    "    feat = ['attr{}_1'.format(i), 'sinc{}_1'.format(i),\n",
    "            'intel{}_1'.format(i), 'fun{}_1'.format(i),\n",
    "            'amb{}_1'.format(i), 'shar{}_1'.format(i)]\n",
    "    if i != 4:\n",
    "        feat.remove('shar{}_1'.format(i))\n",
    "        df = df.drop(feat, axis=1)\n",
    "df = df.drop(['wave'], axis=1)\n",
    "df_male = df.query('gender == 1').drop_duplicates(subset=['iid', 'pid']) \\\n",
    "    .drop(['gender'], axis=1) \\\n",
    "    .dropna()\n",
    "df_female = df.query('gender == 0').drop_duplicates(subset=['iid']) \\\n",
    "    .drop(['gender', 'match', 'int_corr', 'samerace'], axis=1) \\\n",
    "    .dropna()\n",
    "\n",
    "df_female.columns = df_female.columns + '_f'\n",
    "df_female = df_female.drop(['pid_f'], axis=1)\n",
    "df_pair = df_male.join(df_female.set_index('iid_f'),\n",
    "                       on='pid',\n",
    "                       how='inner')\n",
    "df_pair = df_pair.drop(['iid', 'pid'], axis=1)\n",
    "X = df_pair.iloc[:, 1:].values\n",
    "y = df_pair.iloc[:, 0].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,\n",
    "                                                    random_state=123)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 84.2 ms, sys: 2 µs, total: 84.2 ms\n",
      "Wall time: 83.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 563 ms, sys: 0 ns, total: 563 ms\n",
      "Wall time: 564 ms\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на Speed Dating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5829067582453185"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4714901662401143"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5526376588371198"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stand = Pipeline([\n",
    "    (\"clf\", DecisionTreeClassifier(min_samples_split=2, max_depth=10))\n",
    "        \n",
    "])\n",
    "stand.fit(X_train, y_train)\n",
    "f1_score(y_pred=stand.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf_feature_importances</th>\n",
       "      <th>clf_key</th>\n",
       "      <th>myclf_feature_importances</th>\n",
       "      <th>myclf_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.081795</td>\n",
       "      <td>int_corr</td>\n",
       "      <td>0.005247</td>\n",
       "      <td>income_f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.035617</td>\n",
       "      <td>age</td>\n",
       "      <td>0.004533</td>\n",
       "      <td>amb1_1_f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.028540</td>\n",
       "      <td>sinc2_1</td>\n",
       "      <td>0.003833</td>\n",
       "      <td>date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027862</td>\n",
       "      <td>fun1_1</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>fun3_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.026631</td>\n",
       "      <td>amb1_1_f</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>intel3_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.026369</td>\n",
       "      <td>income_f</td>\n",
       "      <td>0.002819</td>\n",
       "      <td>tuition_f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.026160</td>\n",
       "      <td>attr1_1_f</td>\n",
       "      <td>0.002636</td>\n",
       "      <td>fun4_1_f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.025459</td>\n",
       "      <td>fun4_1_f</td>\n",
       "      <td>0.002426</td>\n",
       "      <td>int_corr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.025099</td>\n",
       "      <td>field_cd_f</td>\n",
       "      <td>0.002289</td>\n",
       "      <td>fun2_1_f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.023646</td>\n",
       "      <td>shar1_1</td>\n",
       "      <td>0.002253</td>\n",
       "      <td>intel1_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clf_feature_importances     clf_key  myclf_feature_importances  myclf_key\n",
       "0                 0.081795    int_corr                   0.005247   income_f\n",
       "1                 0.035617         age                   0.004533   amb1_1_f\n",
       "2                 0.028540     sinc2_1                   0.003833       date\n",
       "3                 0.027862      fun1_1                   0.003304     fun3_1\n",
       "4                 0.026631    amb1_1_f                   0.002823   intel3_1\n",
       "5                 0.026369    income_f                   0.002819  tuition_f\n",
       "6                 0.026160   attr1_1_f                   0.002636   fun4_1_f\n",
       "7                 0.025459    fun4_1_f                   0.002426   int_corr\n",
       "8                 0.025099  field_cd_f                   0.002289   fun2_1_f\n",
       "9                 0.023646     shar1_1                   0.002253   intel1_1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_names = df_pair.columns[1:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,\n",
    "                                                    random_state=123)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)\n",
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf.fit(X_train, y_train)\n",
    "my_clf.fit(X_train, y_train)\n",
    "clf_arg = np.argsort(clf.feature_importances_)[::-1]\n",
    "my_clf_arg = np.argsort(my_clf.feature_importances_)[::-1]\n",
    "ss = {\"clf_key\": features_names[clf_arg],\n",
    "      \"clf_feature_importances\": clf.feature_importances_[clf_arg],\n",
    "      \"myclf_key\": features_names[my_clf_arg],\n",
    "      \"myclf_feature_importances\": my_clf.feature_importances_[my_clf_arg]}\n",
    "feature_ss = pd.DataFrame(data=ss)\n",
    "display(feature_ss.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 28, 'min_samples_split': 9}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,\n",
    "                                                    random_state=123)\n",
    "parameters = {\"min_samples_split\": np.arange(2, 10),\n",
    "             \"max_depth\": np.arange(1,100)}\n",
    "clf = GridSearchCV(RandomForestClassifier(), parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
